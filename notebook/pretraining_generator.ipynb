{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/klue/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration train-564fe555afb0b6d8\n",
      "Found cached dataset csv (/opt/ml/.cache/huggingface/datasets/csv/train-564fe555afb0b6d8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|██████████| 1/1 [00:00<00:00, 398.96it/s]\n"
     ]
    }
   ],
   "source": [
    "my_data = load_dataset(\"../dataset/train\", data_files=\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'sentence': '〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.',\n",
       " 'subject_entity': \"{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26, 'type': 'ORG'}\",\n",
       " 'object_entity': \"{'word': '조지 해리슨', 'start_idx': 13, 'end_idx': 18, 'type': 'PER'}\",\n",
       " 'label': 'no_relation',\n",
       " 'source': 'wikipedia'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'sentence': '〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.',\n",
       " 'subject_entity': \"{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26, 'type': 'ORG'}\",\n",
       " 'object_entity': \"{'word': '조지 해리슨', 'start_idx': 13, 'end_idx': 18, 'type': 'PER'}\",\n",
       " 'label': 'no_relation',\n",
       " 'source': 'wikipedia'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = my_data.flatten()\n",
    "my_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([x for x in examples[\"sentence\"]], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/csv/train-564fe555afb0b6d8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-79fa98174ff5314d.arrow\n",
      "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/csv/train-564fe555afb0b6d8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-60665fe9fbc4f26a.arrow\n",
      "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/csv/train-564fe555afb0b6d8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2d612fe1f0ec9f53.arrow\n",
      "Loading cached processed dataset at /opt/ml/.cache/huggingface/datasets/csv/train-564fe555afb0b6d8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-599652eab1756134.arrow\n"
     ]
    }
   ],
   "source": [
    "my_data = my_data.map(preprocess_function,\n",
    "                                batched=True,\n",
    "                                num_proc=4,\n",
    "                                remove_columns=my_data[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lm_dataset \u001b[39m=\u001b[39m my_data\u001b[39m.\u001b[39mmap(group_texts, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_proc\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group_texts' is not defined"
     ]
    }
   ],
   "source": [
    "lm_dataset = my_data.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, TrainingArguments, Trainer\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"monologg/koelectra-base-v3-generator\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp fp16 backend\n",
      "***** Running training *****\n",
      "  Num examples = 32470\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 162360\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53193' max='162360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 53193/162360 1:35:10 < 3:15:20, 9.31 it/s, Epoch 13.10/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.109600</td>\n",
       "      <td>1.913725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.020700</td>\n",
       "      <td>1.814314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.973100</td>\n",
       "      <td>1.779774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>1.764220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.932200</td>\n",
       "      <td>1.735819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.877800</td>\n",
       "      <td>1.718128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.846800</td>\n",
       "      <td>1.692992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.845600</td>\n",
       "      <td>1.678616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.807100</td>\n",
       "      <td>1.664502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.771900</td>\n",
       "      <td>1.649551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.767000</td>\n",
       "      <td>1.630390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.804300</td>\n",
       "      <td>1.617052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.788700</td>\n",
       "      <td>1.614828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n",
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "Configuration saved in ./results/checkpoint-10000/config.json\n",
      "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "Configuration saved in ./results/checkpoint-10500/config.json\n",
      "Model weights saved in ./results/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "Configuration saved in ./results/checkpoint-11000/config.json\n",
      "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-11500\n",
      "Configuration saved in ./results/checkpoint-11500/config.json\n",
      "Model weights saved in ./results/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-12000\n",
      "Configuration saved in ./results/checkpoint-12000/config.json\n",
      "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-12500\n",
      "Configuration saved in ./results/checkpoint-12500/config.json\n",
      "Model weights saved in ./results/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-13000\n",
      "Configuration saved in ./results/checkpoint-13000/config.json\n",
      "Model weights saved in ./results/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-13500\n",
      "Configuration saved in ./results/checkpoint-13500/config.json\n",
      "Model weights saved in ./results/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-14000\n",
      "Configuration saved in ./results/checkpoint-14000/config.json\n",
      "Model weights saved in ./results/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-14500\n",
      "Configuration saved in ./results/checkpoint-14500/config.json\n",
      "Model weights saved in ./results/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-15000\n",
      "Configuration saved in ./results/checkpoint-15000/config.json\n",
      "Model weights saved in ./results/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-15500\n",
      "Configuration saved in ./results/checkpoint-15500/config.json\n",
      "Model weights saved in ./results/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-16000\n",
      "Configuration saved in ./results/checkpoint-16000/config.json\n",
      "Model weights saved in ./results/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-13500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-16500\n",
      "Configuration saved in ./results/checkpoint-16500/config.json\n",
      "Model weights saved in ./results/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-17000\n",
      "Configuration saved in ./results/checkpoint-17000/config.json\n",
      "Model weights saved in ./results/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-17500\n",
      "Configuration saved in ./results/checkpoint-17500/config.json\n",
      "Model weights saved in ./results/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-18000\n",
      "Configuration saved in ./results/checkpoint-18000/config.json\n",
      "Model weights saved in ./results/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-18500\n",
      "Configuration saved in ./results/checkpoint-18500/config.json\n",
      "Model weights saved in ./results/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-19000\n",
      "Configuration saved in ./results/checkpoint-19000/config.json\n",
      "Model weights saved in ./results/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-19500\n",
      "Configuration saved in ./results/checkpoint-19500/config.json\n",
      "Model weights saved in ./results/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-20000\n",
      "Configuration saved in ./results/checkpoint-20000/config.json\n",
      "Model weights saved in ./results/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-17500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-20500\n",
      "Configuration saved in ./results/checkpoint-20500/config.json\n",
      "Model weights saved in ./results/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-21000\n",
      "Configuration saved in ./results/checkpoint-21000/config.json\n",
      "Model weights saved in ./results/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-21500\n",
      "Configuration saved in ./results/checkpoint-21500/config.json\n",
      "Model weights saved in ./results/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-22000\n",
      "Configuration saved in ./results/checkpoint-22000/config.json\n",
      "Model weights saved in ./results/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-22500\n",
      "Configuration saved in ./results/checkpoint-22500/config.json\n",
      "Model weights saved in ./results/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-23000\n",
      "Configuration saved in ./results/checkpoint-23000/config.json\n",
      "Model weights saved in ./results/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-23500\n",
      "Configuration saved in ./results/checkpoint-23500/config.json\n",
      "Model weights saved in ./results/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-24000\n",
      "Configuration saved in ./results/checkpoint-24000/config.json\n",
      "Model weights saved in ./results/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-21500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-24500\n",
      "Configuration saved in ./results/checkpoint-24500/config.json\n",
      "Model weights saved in ./results/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-25000\n",
      "Configuration saved in ./results/checkpoint-25000/config.json\n",
      "Model weights saved in ./results/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-25500\n",
      "Configuration saved in ./results/checkpoint-25500/config.json\n",
      "Model weights saved in ./results/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-26000\n",
      "Configuration saved in ./results/checkpoint-26000/config.json\n",
      "Model weights saved in ./results/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-26500\n",
      "Configuration saved in ./results/checkpoint-26500/config.json\n",
      "Model weights saved in ./results/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-27000\n",
      "Configuration saved in ./results/checkpoint-27000/config.json\n",
      "Model weights saved in ./results/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-27500\n",
      "Configuration saved in ./results/checkpoint-27500/config.json\n",
      "Model weights saved in ./results/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-28000\n",
      "Configuration saved in ./results/checkpoint-28000/config.json\n",
      "Model weights saved in ./results/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-25500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-28500\n",
      "Configuration saved in ./results/checkpoint-28500/config.json\n",
      "Model weights saved in ./results/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-29000\n",
      "Configuration saved in ./results/checkpoint-29000/config.json\n",
      "Model weights saved in ./results/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-29500\n",
      "Configuration saved in ./results/checkpoint-29500/config.json\n",
      "Model weights saved in ./results/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-30000\n",
      "Configuration saved in ./results/checkpoint-30000/config.json\n",
      "Model weights saved in ./results/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-30500\n",
      "Configuration saved in ./results/checkpoint-30500/config.json\n",
      "Model weights saved in ./results/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-31000\n",
      "Configuration saved in ./results/checkpoint-31000/config.json\n",
      "Model weights saved in ./results/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-31500\n",
      "Configuration saved in ./results/checkpoint-31500/config.json\n",
      "Model weights saved in ./results/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-32000\n",
      "Configuration saved in ./results/checkpoint-32000/config.json\n",
      "Model weights saved in ./results/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-29500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-32500\n",
      "Configuration saved in ./results/checkpoint-32500/config.json\n",
      "Model weights saved in ./results/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-33000\n",
      "Configuration saved in ./results/checkpoint-33000/config.json\n",
      "Model weights saved in ./results/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-33500\n",
      "Configuration saved in ./results/checkpoint-33500/config.json\n",
      "Model weights saved in ./results/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-34000\n",
      "Configuration saved in ./results/checkpoint-34000/config.json\n",
      "Model weights saved in ./results/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-34500\n",
      "Configuration saved in ./results/checkpoint-34500/config.json\n",
      "Model weights saved in ./results/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-35000\n",
      "Configuration saved in ./results/checkpoint-35000/config.json\n",
      "Model weights saved in ./results/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-35500\n",
      "Configuration saved in ./results/checkpoint-35500/config.json\n",
      "Model weights saved in ./results/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-36000\n",
      "Configuration saved in ./results/checkpoint-36000/config.json\n",
      "Model weights saved in ./results/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-36500\n",
      "Configuration saved in ./results/checkpoint-36500/config.json\n",
      "Model weights saved in ./results/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-34000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-37000\n",
      "Configuration saved in ./results/checkpoint-37000/config.json\n",
      "Model weights saved in ./results/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-37500\n",
      "Configuration saved in ./results/checkpoint-37500/config.json\n",
      "Model weights saved in ./results/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-38000\n",
      "Configuration saved in ./results/checkpoint-38000/config.json\n",
      "Model weights saved in ./results/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-38500\n",
      "Configuration saved in ./results/checkpoint-38500/config.json\n",
      "Model weights saved in ./results/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-39000\n",
      "Configuration saved in ./results/checkpoint-39000/config.json\n",
      "Model weights saved in ./results/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-39500\n",
      "Configuration saved in ./results/checkpoint-39500/config.json\n",
      "Model weights saved in ./results/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-40000\n",
      "Configuration saved in ./results/checkpoint-40000/config.json\n",
      "Model weights saved in ./results/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-40500\n",
      "Configuration saved in ./results/checkpoint-40500/config.json\n",
      "Model weights saved in ./results/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-38000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-41000\n",
      "Configuration saved in ./results/checkpoint-41000/config.json\n",
      "Model weights saved in ./results/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-41500\n",
      "Configuration saved in ./results/checkpoint-41500/config.json\n",
      "Model weights saved in ./results/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-42000\n",
      "Configuration saved in ./results/checkpoint-42000/config.json\n",
      "Model weights saved in ./results/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-42500\n",
      "Configuration saved in ./results/checkpoint-42500/config.json\n",
      "Model weights saved in ./results/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-43000\n",
      "Configuration saved in ./results/checkpoint-43000/config.json\n",
      "Model weights saved in ./results/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-43500\n",
      "Configuration saved in ./results/checkpoint-43500/config.json\n",
      "Model weights saved in ./results/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-44000\n",
      "Configuration saved in ./results/checkpoint-44000/config.json\n",
      "Model weights saved in ./results/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-44500\n",
      "Configuration saved in ./results/checkpoint-44500/config.json\n",
      "Model weights saved in ./results/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-42000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-45000\n",
      "Configuration saved in ./results/checkpoint-45000/config.json\n",
      "Model weights saved in ./results/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-45500\n",
      "Configuration saved in ./results/checkpoint-45500/config.json\n",
      "Model weights saved in ./results/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-46000\n",
      "Configuration saved in ./results/checkpoint-46000/config.json\n",
      "Model weights saved in ./results/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-46500\n",
      "Configuration saved in ./results/checkpoint-46500/config.json\n",
      "Model weights saved in ./results/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-47000\n",
      "Configuration saved in ./results/checkpoint-47000/config.json\n",
      "Model weights saved in ./results/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-47500\n",
      "Configuration saved in ./results/checkpoint-47500/config.json\n",
      "Model weights saved in ./results/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-48000\n",
      "Configuration saved in ./results/checkpoint-48000/config.json\n",
      "Model weights saved in ./results/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-48500\n",
      "Configuration saved in ./results/checkpoint-48500/config.json\n",
      "Model weights saved in ./results/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-48500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-46000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-49000\n",
      "Configuration saved in ./results/checkpoint-49000/config.json\n",
      "Model weights saved in ./results/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-49500\n",
      "Configuration saved in ./results/checkpoint-49500/config.json\n",
      "Model weights saved in ./results/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-50000\n",
      "Configuration saved in ./results/checkpoint-50000/config.json\n",
      "Model weights saved in ./results/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-50500\n",
      "Configuration saved in ./results/checkpoint-50500/config.json\n",
      "Model weights saved in ./results/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-51000\n",
      "Configuration saved in ./results/checkpoint-51000/config.json\n",
      "Model weights saved in ./results/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-48500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-51500\n",
      "Configuration saved in ./results/checkpoint-51500/config.json\n",
      "Model weights saved in ./results/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-52000\n",
      "Configuration saved in ./results/checkpoint-52000/config.json\n",
      "Model weights saved in ./results/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-52500\n",
      "Configuration saved in ./results/checkpoint-52500/config.json\n",
      "Model weights saved in ./results/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 32470\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-53000\n",
      "Configuration saved in ./results/checkpoint-53000/config.json\n",
      "Model weights saved in ./results/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-50500] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=40,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=my_data[\"train\"],\n",
    "    eval_dataset=my_data[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "old_collator = trainer.data_collator\n",
    "trainer.data_collator = lambda data: dict(old_collator(data))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"./results/checkpoint-53000\")\n",
    "fill_mask = pipeline(task=\"fill-mask\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '소련군에서 그의 이름도 중국식의 진지첸으로 조선인으로서의 정체성도 확고히 했다.',\n",
       "  'score': 0.1746564358472824,\n",
       "  'token': 23300,\n",
       "  'token_str': '확고히'},\n",
       " {'sequence': '소련군에서 그의 이름도 중국식의 진지첸으로 조선인으로서의 정체성도 분명히 했다.',\n",
       "  'score': 0.11067641526460648,\n",
       "  'token': 8370,\n",
       "  'token_str': '분명히'},\n",
       " {'sequence': '소련군에서 그의 이름도 중국식의 진지첸으로 조선인으로서의 정체성도 모른다고 했다.',\n",
       "  'score': 0.07074985653162003,\n",
       "  'token': 18159,\n",
       "  'token_str': '모른다고'},\n",
       " {'sequence': '소련군에서 그의 이름도 중국식의 진지첸으로 조선인으로서의 정체성도 명확히 했다.',\n",
       "  'score': 0.06588910520076752,\n",
       "  'token': 13724,\n",
       "  'token_str': '명확히'},\n",
       " {'sequence': '소련군에서 그의 이름도 중국식의 진지첸으로 조선인으로서의 정체성도 함께 했다.',\n",
       "  'score': 0.051871009171009064,\n",
       "  'token': 6261,\n",
       "  'token_str': '함께'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"소련군에서 그의 이름도 중국식의 진지첸으로 조선인으로서의 정체성도 [MASK]했다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('klue')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdf5d1a2b21d5315a0b7a0779e9f9212b6d3b593604d472f2d14684b88d9f7c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
