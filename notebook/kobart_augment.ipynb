{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/klue/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 616/616 [00:00<00:00, 327kB/s]\n",
      "Downloading: 100%|██████████| 2.24G/2.24G [00:36<00:00, 61.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 5.07M/5.07M [00:01<00:00, 3.12MB/s]\n",
      "Downloading: 100%|██████████| 9.10M/9.10M [00:01<00:00, 4.92MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[tensor(0), tensor(6), tensor(90459), tensor(...\n",
       "1        [[tensor(0), tensor(23646), tensor(13902), ten...\n",
       "2        [[tensor(0), tensor(341), tensor(88774), tenso...\n",
       "3        [[tensor(0), tensor(6), tensor(83654), tensor(...\n",
       "4        [[tensor(0), tensor(28980), tensor(2680), tens...\n",
       "                               ...                        \n",
       "32465    [[tensor(0), tensor(9397), tensor(7641), tenso...\n",
       "32466    [[tensor(0), tensor(37668), tensor(12284), ten...\n",
       "32467    [[tensor(0), tensor(6), tensor(34433), tensor(...\n",
       "32468    [[tensor(0), tensor(106752), tensor(88356), te...\n",
       "32469    [[tensor(0), tensor(26191), tensor(46364), ten...\n",
       "Name: sentence, Length: 32470, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sentences.apply(lambda x: tokenizer(x, return_tensors=\"pt\")[\"input_ids\"])\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,  23646,  13902,    469,  96685,   1571,  11095,  44623,   5645,\n",
       "          15960,   7641,   1280,   3032,   8825,   5301,   7641,   1280, 128682,\n",
       "         219052,   7641,    469,  23526,   8177,  30679,  19625,  42482,    480,\n",
       "          51638,   7641,   1963,  36192,  10047,   7641,    132,    713,  72047,\n",
       "             16,   1654,  11105,  39191,  10047,   9514,      5,      2]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Any, Optional, Tuple\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_mask_tokens(inputs: Any,tokenizer, mlm_probability:float=0.1,special_tokens_mask: Optional[Any] = None) -> Tuple[Any, Any]:\n",
    "    \"\"\"\n",
    "    Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    labels = inputs.clone()\n",
    "    # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    if special_tokens_mask is None:\n",
    "        special_tokens_mask = [\n",
    "            tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "        ]\n",
    "        special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "    else:\n",
    "        special_tokens_mask = special_tokens_mask.bool()\n",
    "\n",
    "    probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 1,dtype=torch.float32)).bool() & masked_indices\n",
    "    print(indices_replaced)\n",
    "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    # # 10% of the time, we replace masked input tokens with random word\n",
    "    # indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "    # random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "    # inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[     0,  23646,  13902,    469,  96685,   1571,  11095,  44623,   5645,\n",
       "          15960,   7641,   1280,   3032, 250001,   5301,   7641,   1280, 128682,\n",
       "         219052,   7641,    469,  23526,   8177,  30679,  19625,  42482, 250001,\n",
       "          51638,   7641,   1963,  36192, 250001,   7641,    132,    713,  72047,\n",
       "             16,   1654,  11105,  39191,  10047,   9514,      5,      2]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch_mask_tokens(sentences[1], tokenizer=tokenizer, mlm_probability=0.1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> 호남이 기반인 바른미래당·대<mask>신당·민주평화당이 우여곡절 끝<mask> 합당해 민<mask>당(가칭)으로 재탄생한다.</s>'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_sent = tokenizer.decode(x[0])\n",
    "mask_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/klue/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.11501485854387283,\n",
       "   'token': 6775,\n",
       "   'token_str': '우',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대우 신당·민주평화당이 우여곡절 끝<mask> 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.10313916951417923,\n",
       "   'token': 5050,\n",
       "   'token_str': '선',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대선 신당·민주평화당이 우여곡절 끝<mask> 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.10303967446088791,\n",
       "   'token': 5102,\n",
       "   'token_str': '치',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대치 신당·민주평화당이 우여곡절 끝<mask> 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.10192589461803436,\n",
       "   'token': 3665,\n",
       "   'token_str': '화',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대화 신당·민주평화당이 우여곡절 끝<mask> 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.07685703784227371,\n",
       "   'token': 8825,\n",
       "   'token_str': '안',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대안 신당·민주평화당이 우여곡절 끝<mask> 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'}],\n",
       " [{'score': 0.9984962940216064,\n",
       "   'token': 480,\n",
       "   'token_str': '에',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝에 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.00044039165368303657,\n",
       "   'token': 10459,\n",
       "   'token_str': '내',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝내 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.0001803348568500951,\n",
       "   'token': 1654,\n",
       "   'token_str': '으로',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝으로 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.00010543626558501273,\n",
       "   'token': 1180,\n",
       "   'token_str': '에서',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝에서 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.00010198436939390376,\n",
       "   'token': 4,\n",
       "   'token_str': ',',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝, 합당해 민<mask> 당(가칭)으로 재탄생한다.</s></s>'}],\n",
       " [{'score': 0.2524968385696411,\n",
       "   'token': 7094,\n",
       "   'token_str': '중',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝<mask> 합당해 민중 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.1314842700958252,\n",
       "   'token': 10047,\n",
       "   'token_str': '생',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝<mask> 합당해 민생 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.10345899313688278,\n",
       "   'token': 367,\n",
       "   'token_str': '의',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝<mask> 합당해 민의 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.057851117104291916,\n",
       "   'token': 36192,\n",
       "   'token_str': '민',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝<mask> 합당해 민 민 당(가칭)으로 재탄생한다.</s></s>'},\n",
       "  {'score': 0.04327744245529175,\n",
       "   'token': 36564,\n",
       "   'token_str': '족',\n",
       "   'sequence': '<s><s> 호남이 기반인 바른미래당·대<mask> 신당·민주평화당이 우여곡절 끝<mask> 합당해 민족 당(가칭)으로 재탄생한다.</s></s>'}]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task(mask_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내가 생각한 MASK토큰을 처리하는 방식?\n",
    "##### 1. x%비율로 먼저 마스킹 처리를 하고,일괄적으로 MASK 토큰을 처리한다.\n",
    "##### 2. x%비율로, 어느 인덱스(토큰의 위치)를 마스킹할지만 먼저 체크하고, for문을 돌면서 k개의 MASK토큰에 대해 k번 추측을 한다.\n",
    "\n",
    "1.의 장점\n",
    "\n",
    "    1. 2번의 방식에 비해 k배 빠르다.\n",
    "    2. 단점 -> 마스킹한 토큰의 추측이 정확하지 않을 수 있다.하지만 반드시 안좋은 건 아닐것이다..\n",
    "\n",
    "2.의 장점\n",
    "\n",
    "    1. 1에비해 추측이 정확하다. \n",
    "    2. 속도가 느리다..\n",
    "\n",
    "#### 추가로 생각해 볼 것 -> score기준을 어떤 식으로 할 것인가?\n",
    "예를 들어 생각해보면.. score 를 0.90점 이상인 값들만 augment를 한다고 하면, 이 정도로 모델이 강하게 예측한 경우는 mask하기전 토큰과 동일할 확률이 높다. 이말인 즉슨, 버리는 mask가 많을 것이다.\n",
    "반대로 score가 너무 낮으면, 문장의 의미가 변해서 augment한 데이터의 퀄리티가 떨어져 안하니만 못한 수준이 될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> 호남이 기반인 바른<mask>래당·대안신당·민주평화당이 우여곡절 끝에<mask>당해 민생당(가<mask>)으로 재탄생한다<mask></s>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/klue/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8786227107048035,\n",
       " 'token': 5645,\n",
       " 'token_str': '미',\n",
       " 'sequence': '<s><s> 호남이 기반인 바른미 래당·대안신당·민주평화당이 우여곡절 끝에<mask> 당해 민생당(가<mask> )으로 재탄생한다<mask></s></s>'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task(mask_sent)[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('klue')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdf5d1a2b21d5315a0b7a0779e9f9212b6d3b593604d472f2d14684b88d9f7c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
